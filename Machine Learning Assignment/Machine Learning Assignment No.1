1)
Machine learning is a concept that computer programm can learn and adopt new data without human intervention.
 
2)
fraudulent credit card transactions
Spam detection in email
cancer diagnosis
automatically driving vehicle

3)
we split up the data containing known response variable values into two pieces.The training set is used to train the algorithm, and then we use the trained model on the test set to predict the response variable values that are already known.

4)
Regression
Classification

5)
Visualization
Dimensionality reduction
Clustering
Association rule learning

6)
Reinforcement learning approach.
it is a system where "agent" observes the environment,selects and performs action,then receives a reward or punishment based on the result of the action and over time agent learn itself what is a most productive strategy.

7)
We will use a clustering algorithm that can find a decision boundaries in the groups automatically.this is an unsupervised approch.
If we already knows the customer categories then we will use a supervised approch that is classification algorithm.


8)
I would consider this as supervised learning problem.because human have a genaral idea about what spam is and what it isn't.we can use this notion to create a labeled dataset for an algorithm to learn from.


9)
An online learning system learns from the new data on the fly.As a result,system trained incrementlly either by using one example at a time or using a mini batch approch.This keep each learning step cheap.


10)
It is use when a dataset is too large to fit into computer's memory.The algorithm loads part of data,runs a training step,then repeats the precess untill it as run on all the data.


11)
Instance based learning algorithms use a measure of similarity to generalize to new cases.In an instance base learning system,the algorithm learns the examples by heart then uses the similarity measure to generalize.


12)
Model parameters-This are the parameters in the model that must be determined using the training data set.
Hyper parameters-This are the adjustable parameters that must be tuned in order to obtained a model with optimal performance.


13)
A model based learning algorithm needa a optimal value of the paramters to generalise the new model or example.
The most popular method is minimizing the loss & accuracy or regularization.
It can make a prediction using the set parameters.


14)
Less amount of training data.
poor quality of data.
Irrelevant features.
Nonrepresentative training data.


15)
This is a case where,model is overlifting the training data.To couteract overlifting,we can reduce the complexity of the model by removing features or constraining the parameters.We could gather more data.finally we can reduce noisiness in data by fixing errors and removing outliers.


16)
Test set is a secondary data set that is used to set a machine learning program after it has been trained or an initial training data set.
the point of data set is to give a final,unbiased performance measure of your entire model building process.


17)
It is a set of data used to train artificial intelligence with the goal of finding and optimizing the best model to solve a given problem.
Validation sets are used to select and tune the final AI model.


18)
The goal of dev-set is to rank the models in term of their accuracy and helps us decide which model to proceed further with. Using Dev set we rank all our models in terms of their accuracy and pick the best performing model.
For use we can make three sets one for train,one for dev and one for test, and you can make a structure like this with 80% in a traing set,10% in a dev set and 10% in a test set.  
    
19)
Model will not be generalizable to new examples.